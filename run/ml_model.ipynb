{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Yx4koCb0zT8M"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFCWaHgpG3qb"
      },
      "source": [
        "\n",
        "\n",
        "*   Võ Đình Tứ \n",
        "*   Hồ Anh Dũng\n",
        "*   Nguyễn Hữu Trường\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNfA73i6Io8K"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJwumj8UPCCN"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pip install sparknlp\n",
        "!sudo apt install openjdk-8-jdk\n",
        "!sudo update-alternatives --config java\n",
        "! java -version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUXDJlylPJxk"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as f \n",
        "import pandas as pd\n",
        "import html\n",
        "from pyspark.sql.types import StructField,IntegerType, StructType,StringType, FloatType\n",
        "from pyspark.sql.functions import col, when , regexp_replace\n",
        "from pyspark.sql.functions import udf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecbWtnNqPdqX"
      },
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKaZdSFHPgsF"
      },
      "source": [
        "sc = spark.sparkContext\n",
        "path = \"/content/drive/MyDrive/bigdata/IMDB_review/part-06.json\"\n",
        "data = spark.read.json(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKgleNKcPjx-"
      },
      "source": [
        "data=data.dropna(how=\"any\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nv-XSspPmeU"
      },
      "source": [
        "data = data.withColumn(\"sentiment\",when(data.rating < 5  ,\"negative\").when((data.rating >= 5)&(data.rating<7),\"neutral\").when(data.rating >= 7,\"positive\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OQmxlXJPqUh"
      },
      "source": [
        "data_clean=data.select(\"review_detail\",\"sentiment\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSjn_wE1PtKu"
      },
      "source": [
        "train, test,val = data_clean.randomSplit([2.0,0.5,7.5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXdFSrnsPvHM"
      },
      "source": [
        "user_regex = r\"(@\\w{1,15})\"\n",
        "hashtag_replace_regex = \"#(\\w{1,})\"\n",
        "url_regex = r\"((https?|ftp|file):\\/{2,3})+([-\\w+&@#/%=~|$?!:,.]*)|(www.)+([-\\w+&@#/%=~|$?!:,.]*)\"\n",
        "email_regex = r\"[\\w.-]+@[\\w.-]+\\.[a-zA-Z]{1,}\"\n",
        "i_regex = r\"i \"\n",
        "\n",
        "def cleaning_process(data):\n",
        "            # Loại bỏ @Mention khỏi text\n",
        "    data=(data.withColumn(\"review_detail\",f.regexp_replace(f.col(\"review_detail\"), user_regex, \"\")) \n",
        "            # Loại bỏ #Hashtag khỏi text\n",
        "            .withColumn(\"review_detail\",f.regexp_replace(f.col(\"review_detail\"), hashtag_replace_regex, \"$1\"))\n",
        "            # Loại bỏ URL khỏi text\n",
        "            .withColumn(\"review_detail\",f.regexp_replace(f.col(\"review_detail\"), url_regex, \"\")) \n",
        "            # Loại bỏ Email khỏi text\n",
        "            .withColumn(\"review_detail\",f.regexp_replace(f.col(\"review_detail\"), email_regex, \"\"))\n",
        "            # Loại bỏ số cũng như các ký tự khỏi đoạn text\n",
        "            .withColumn(\"review_detail\",f.regexp_replace(f.col(\"review_detail\"), \"[^a-zA-Z]\", \" \"))\n",
        "            # Loại bỏ các khoảng trắng thừa trong câu\n",
        "            .withColumn(\"review_detail\",f.regexp_replace(f.col(\"review_detail\"), \" +\", \" \"))\n",
        "            # Loại vỏ các khoảng trắng đầu và cuối câu\n",
        "            .withColumn(\"review_detail\",f.trim(f.col(\"review_detail\")))\\\n",
        "            # Chuẩn hoá viết thường\n",
        "            .withColumn(\"review_detail\",f.lower(f.col(\"review_detail\")))\n",
        "            # Giữ lại các dòng mà đoạn text có nội dung \n",
        "            .filter(f.col(\"review_detail\") != \"\"))\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgmBpLf0PwAK"
      },
      "source": [
        "dl_train = cleaning_process(train)\n",
        "dl_test = cleaning_process(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oX8Aj3mPz5L"
      },
      "source": [
        "dl_train.toPandas().to_csv(\"/content/drive/MyDrive/bigdata/df_train.csv\",index = 0,header = True)\n",
        "dl_test.toPandas().to_csv(\"/content/drive/MyDrive/bigdata/df_test.csv\",index = 0,header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_SrZDgrI4YM"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akhZGaZeIzOw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm_fgzER5buk"
      },
      "source": [
        "## Setup colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-bPCycyx06S",
        "outputId": "1877ecd9-a935-4700-9d82-6e2aaec9011c"
      },
      "source": [
        "# Kết nối driver\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOenaMAFs8-U"
      },
      "source": [
        "#! pip install --ignore-installed pyspark==2.4.4\n",
        "#! pip install --ignore-installed spark-nlp==2.6.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52xOpll3HZWP"
      },
      "source": [
        "## Cài đặt các thư viện và java"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEDw0Ipsx93n",
        "outputId": "a9e78ba2-dda0-40a9-b3bc-2e6c4ee6d9aa"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pip install sparknlp\n",
        "!sudo apt install openjdk-8-jdk\n",
        "!sudo update-alternatives --config java\n",
        "! java -version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 61 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 64.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=fd20a713a3bf8c3f63538fe1512854e180da00cb166b1257e5b4c97b7d3482eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
            "Collecting findspark\n",
            "  Downloading findspark-1.4.2-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-1.4.2\n",
            "Collecting sparknlp\n",
            "  Downloading sparknlp-1.0.0-py3-none-any.whl (1.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sparknlp) (1.19.5)\n",
            "Collecting spark-nlp\n",
            "  Downloading spark_nlp-3.1.3-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 4.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp, sparknlp\n",
            "Successfully installed spark-nlp-3.1.3 sparknlp-1.0.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  gvfs openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 15 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 43.5 MB of archives.\n",
            "After this operation, 163 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u292-b10-0ubuntu1~18.04 [28.2 MB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u292-b10-0ubuntu1~18.04 [69.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u292-b10-0ubuntu1~18.04 [8,284 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u292-b10-0ubuntu1~18.04 [1,644 kB]\n",
            "Fetched 43.5 MB in 2s (19.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../11-openjdk-8-jre-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../12-openjdk-8-jre_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../13-openjdk-8-jdk-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../14-openjdk-8-jdk_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "There are 2 choices for the alternative java (providing /usr/bin/java).\n",
            "\n",
            "  Selection    Path                                            Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode\n",
            "  2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_292\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10)\n",
            "OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS6cmhayqloq"
      },
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9t89-pRHujx"
      },
      "source": [
        "## Khai báo spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "aqKODPO5Hq0q",
        "outputId": "e6afbdcb-728a-4037-a460-64d4aa7a6092"
      },
      "source": [
        "spark = sparknlp.start(gpu = True) # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version 3.1.1\n",
            "Apache Spark version: 3.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b37c819980c2:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fc46ceec290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFzle5naIbos"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG-944EEqls-"
      },
      "source": [
        "schema1 = \"review_detail STRING, sentiment STRING\"\n",
        "data_train = spark.read.csv(\"/content/drive/MyDrive/bigdata/df_train.csv\", header=True,schema=schema1)\n",
        "\n",
        "data_test = spark.read.csv(\"/content/drive/MyDrive/bigdata/df_test.csv\", header=True,schema=schema1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KeAOfgtEzZW",
        "outputId": "cdb9d2de-9c58-4382-b5cb-417da4154e2c"
      },
      "source": [
        "data_train.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+---------+\n",
            "|       review_detail|sentiment|\n",
            "+--------------------+---------+\n",
            "|spoilers ahead a ...| positive|\n",
            "|spoilers a hot sh...|  neutral|\n",
            "|spoilers for thos...|  neutral|\n",
            "|mild spoilers das...|  neutral|\n",
            "|spoilers cop jack...| negative|\n",
            "|warning major spo...| positive|\n",
            "|spoilers and no i...| negative|\n",
            "|spoilers this ins...| positive|\n",
            "|spoilers the very...| positive|\n",
            "|may contain mild ...| positive|\n",
            "|a lot like love i...| positive|\n",
            "|a mighty wind was...| positive|\n",
            "|bought it watched...| positive|\n",
            "|heist directed by...| positive|\n",
            "|documentary filmm...| negative|\n",
            "|i m not worth it ...| positive|\n",
            "|did not return fr...| positive|\n",
            "|and her love for ...| positive|\n",
            "|the beat is too s...| positive|\n",
            "|all the marbles i...|  neutral|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpNxTeUiJGG6"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIz1K2BGrCcZ"
      },
      "source": [
        "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, OneHotEncoder, StringIndexer, VectorAssembler, SQLTransformer\n",
        "from pyspark.sql.functions import col, when , regexp_replace\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bQ_pXIuqeEH",
        "outputId": "4b3f4c6a-d24a-41bc-ecc9-7a2f412025f9"
      },
      "source": [
        "%%time\n",
        "\n",
        "document_assembler = DocumentAssembler() \\\n",
        "      .setInputCol(\"review_detail\") \\\n",
        "      .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "      \n",
        "normalizer = Normalizer() \\\n",
        "      .setInputCols([\"token\"]) \\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"normalized\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "stemmer = Stemmer() \\\n",
        "      .setInputCols([\"cleanTokens\"]) \\\n",
        "      .setOutputCol(\"stem\")\n",
        "\n",
        "finisher = Finisher() \\\n",
        "      .setInputCols([\"stem\"]) \\\n",
        "      .setOutputCols([\"token_features\"]) \\\n",
        "      .setOutputAsArray(True) \\\n",
        "      .setCleanAnnotations(False)\n",
        "\n",
        "hashing_tf = HashingTF(inputCol = \"token_features\",\n",
        "                       outputCol = \"raw_feature\")\n",
        "\n",
        "idf = IDF(inputCol = \"raw_feature\",\n",
        "          outputCol = \"features\",\n",
        "          minDocFreq = 5) \n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25.6 ms, sys: 13.1 ms, total: 38.6 ms\n",
            "Wall time: 213 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDySC-x4P92D"
      },
      "source": [
        "### Machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx4koCb0zT8M"
      },
      "source": [
        "#### TF-IDF vectorizer + Logistic Regeression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pL3phVZqeGl"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(labelCol = \"label\",maxIter=10, regParam=0.3, elasticNetParam=0)\n",
        "\n",
        "nlp_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            hashing_tf,\n",
        "            idf,\n",
        "            label_stringIdx,\n",
        "            lr\n",
        "            ])\n",
        "\n",
        "\n",
        "lr_model= nlp_pipeline.fit(data_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOtmTGPvqeI3"
      },
      "source": [
        "pred_lr = lr_model.transform(data_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je1_6P8CEFQK"
      },
      "source": [
        "pred_lr.show(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXmnt78CqeLa",
        "outputId": "dbcfa6c8-f845-4d64-c9dc-bf48e26d3a65"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "df_lr = pred_lr.select('review_detail','label','prediction').toPandas()\n",
        "print(classification_report(df_lr.label,df_lr.prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.97      0.88     10371\n",
            "         1.0       0.79      0.56      0.66      3014\n",
            "         2.0       0.40      0.07      0.12      1771\n",
            "\n",
            "    accuracy                           0.79     15156\n",
            "   macro avg       0.66      0.54      0.55     15156\n",
            "weighted avg       0.75      0.79      0.74     15156\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I78qsMhD5Z94",
        "outputId": "39c28fdc-b700-431e-bd89-393537ed9590"
      },
      "source": [
        "lr_model.save(\"/content/drive/MyDrive/bigdata/NLP_model_lr\")\n",
        "shutil.make_archive(\"model\",\"zip\",\"/content/drive/MyDrive/bigdata/NLP_model_lr\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/model.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEIUshvNzYNH"
      },
      "source": [
        "#### TF-IDF vectorizer + NavieBayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovit5Y8yqePY"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "Nb = NaiveBayes(smoothing=111)\n",
        "\n",
        "nlp_pipeline_NB = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            stemmer, \n",
        "            finisher,\n",
        "            hashing_tf,\n",
        "            idf,\n",
        "            label_stringIdx,\n",
        "            Nb\n",
        "            ])\n",
        "\n",
        "\n",
        "NB_model= nlp_pipeline_NB.fit(data_train)\n",
        "\n",
        "pred_NB = NB_model.transform(data_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-OcIG8nqeRl",
        "outputId": "c489aaed-08ff-4653-ad0b-0e5db362a428"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "df_NB = pred_NB.select('review_detail','label','prediction').toPandas()\n",
        "print(classification_report(df_NB.label,df_NB.prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      1.00      0.81     10371\n",
            "         1.0       1.00      0.00      0.00      3014\n",
            "         2.0       0.00      0.00      0.00      1771\n",
            "\n",
            "    accuracy                           0.68     15156\n",
            "   macro avg       0.56      0.33      0.27     15156\n",
            "weighted avg       0.67      0.68      0.56     15156\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxP3rfkRQLdG"
      },
      "source": [
        "### Deeplearning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moPi1UX2Jaaq"
      },
      "source": [
        "#### Bertembedding + ClassifierDLApproach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1ZP5FAaqeT3",
        "outputId": "70862d8c-6991-4faf-f5dc-334b32fcdd9b"
      },
      "source": [
        "\n",
        "bert_embeddings = BertEmbeddings().pretrained(name='small_bert_L4_256', lang='en') \\\n",
        "    .setInputCols([\"document\",'token'])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\\\n",
        "    .setLabelColumn(\"sentiment\")\\\n",
        "    .setMaxEpochs(10)\\\n",
        "    .setLr(0.001)\\\n",
        "    .setBatchSize(8)\\\n",
        "    .setEnableOutputLogs(True)\n",
        "\n",
        "Dl_model = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    tokenizer,\n",
        "    bert_embeddings,\n",
        "    embeddingsSentence,\n",
        "    classsifierdl\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "small_bert_L4_256 download started this may take some time.\n",
            "Approximate size to download 40.5 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXTe0AT4qeWZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHm1yCBqehJ"
      },
      "source": [
        "%%time\n",
        "bert_model= Dl_model.fit(data_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpOpCFkvQ5fs"
      },
      "source": [
        "pred_bert = bert_model.transform(data_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmpT6tkBTnoN",
        "outputId": "5246b701-6e0e-46ec-dbd6-8d9e6f40191d"
      },
      "source": [
        "pred_bert.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|       review_detail|sentiment|            document|               token|          embeddings| sentence_embeddings|               class|\n",
            "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|possible mild spo...| negative|[{document, 0, 72...|[{token, 0, 7, po...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 72...|\n",
            "|a lot like love i...| positive|[{document, 0, 80...|[{token, 0, 0, a,...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 80...|\n",
            "|a worthy sequel b...| negative|[{document, 0, 21...|[{token, 0, 0, a,...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 21...|\n",
            "|th hour is a very...| positive|[{document, 0, 35...|[{token, 0, 1, th...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 35...|\n",
            "|femmes is such a ...| negative|[{document, 0, 13...|[{token, 0, 5, fe...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 13...|\n",
            "|a gentleman s gam...|  neutral|[{document, 0, 67...|[{token, 0, 0, a,...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 67...|\n",
            "|a good thief is a...| positive|[{document, 0, 66...|[{token, 0, 0, a,...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 66...|\n",
            "|a nightmare on el...| positive|[{document, 0, 66...|[{token, 0, 0, a,...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 66...|\n",
            "|a tale of two sis...| positive|[{document, 0, 17...|[{token, 0, 0, a,...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 17...|\n",
            "|a woman called go...| positive|[{document, 0, 96...|[{token, 0, 0, a,...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 96...|\n",
            "|a i is not a film...| positive|[{document, 0, 79...|[{token, 0, 0, a,...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 79...|\n",
            "|about schmidt pre...| positive|[{document, 0, 10...|[{token, 0, 4, ab...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 10...|\n",
            "|against the wall ...| positive|[{document, 0, 40...|[{token, 0, 6, ag...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 40...|\n",
            "|aldrich ames trai...|  neutral|[{document, 0, 46...|[{token, 0, 6, al...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 46...|\n",
            "|all or nothing is...| positive|[{document, 0, 37...|[{token, 0, 2, al...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 37...|\n",
            "|almost famous is ...|  neutral|[{document, 0, 96...|[{token, 0, 5, al...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 96...|\n",
            "|along the way nam...| positive|[{document, 0, 68...|[{token, 0, 4, al...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 68...|\n",
            "|always remember i...| positive|[{document, 0, 48...|[{token, 0, 5, al...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 48...|\n",
            "|american beauty h...|  neutral|[{document, 0, 31...|[{token, 0, 7, am...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 31...|\n",
            "|american pie is a...| positive|[{document, 0, 22...|[{token, 0, 7, am...|[{word_embeddings...|[{sentence_embedd...|[{category, 0, 22...|\n",
            "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVByvisj3YzC"
      },
      "source": [
        "preds_df = pred_bert.select('review_detail','sentiment',\"class.result\").toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuoxYhAfUTEB"
      },
      "source": [
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuJKFZmzZ-MX",
        "outputId": "77b1b295-a2dd-46b5-ced3-d0813e0f6bfb"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print (classification_report(preds_df['result'], preds_df['sentiment']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.51      0.57      0.54      2682\n",
            "     neutral       0.00      0.00      0.00         0\n",
            "    positive       0.93      0.76      0.84     12291\n",
            "\n",
            "    accuracy                           0.73     14973\n",
            "   macro avg       0.48      0.44      0.46     14973\n",
            "weighted avg       0.85      0.73      0.78     14973\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWyAcB0V63LU"
      },
      "source": [
        "#### Glove+ ClassifierDLApproach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "sSC0YVrL7Vhs",
        "outputId": "9ddc915c-67dc-451c-c77a-a8e0cd330725"
      },
      "source": [
        "\n",
        "use = UniversalSentenceEncoder.pretrained('tfhub_use', lang=\"en\") \\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "classifier = SentimentDLModel().pretrained('sentimentdl_use_imdb')\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\n",
        "    .setLabelColumn(\"sentiment\")\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[document_assembler,\n",
        "                                use,\n",
        "                                classifier\n",
        "                                ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-0f4d974f3b77>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    .setLabelColumn(\"sentiment\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeAnUgng-yF9"
      },
      "source": [
        "embeddings = WordEmbeddingsModel().pretrained(\"glove_100d\")\\\n",
        "    .setInputCols(['document','tokens'])\\\n",
        "    .setOutputCol('word_embeddings')\n",
        "sentence_embeddings = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"word_embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "classifier = SentimentDLModel().pretrained('sentimentdl_glove_imdb')\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"sentiment\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruqvknVXZ_aq"
      },
      "source": [
        "# Real-time sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pp20nz_aIb5"
      },
      "source": [
        "## Carwl Data review IMDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrMaKh5ydPeb"
      },
      "source": [
        "! pip install selenium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "988riO5HdRy3"
      },
      "source": [
        "from selenium import webdriver\n",
        "import time, urllib.parse\n",
        "from bs4 import BeautifulSoup as soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjylfU79dk3n"
      },
      "source": [
        "d = webdriver.Chrome(r'C:\\Program Files\\crawldata\\chromedriver')\n",
        "d.get((l:='https://www.imdb.com/title/tt5034838/reviews/?ref_=tt_ql_urv'))\n",
        "while int(d.execute_script(\"return Array.from(document.querySelectorAll('#main .review-container')).length\")) < int((d.execute_script(\"return document.querySelector('.header span').textContent\").split()[0]).replace(',','')):\n",
        "   d.execute_script('document.querySelector(\".ipl-load-more__button\").click()')\n",
        "   time.sleep(3)\n",
        "\n",
        "r = [{#'score':i.select_one('span.rating-other-user-rating span:nth-of-type(1)').get_text(strip=True),\n",
        "      #'title':i.select_one('a.title').get_text(strip=True),\n",
        "      'reviewer_name':(j:=i.select_one('.display-name-link > a')).get_text(strip=True),\n",
        "      #'reviewer_link':urllib.parse.urljoin(l, j['href']),\n",
        "      #'date':(j:=i.select_one('.display-name-link > .review-date')).get_text(strip=True),\n",
        "       #'date':i.select_one('.display-name-link > .review-date').get_date(),\n",
        "       'date':i.select_one('.review-date').get_text(strip=True),\n",
        "      'text':i.select_one('.content > .text').get_text(strip=True)\n",
        "    } \n",
        "    for i in soup(d.page_source, 'html.parser').select('#main .review-container')]\n",
        "\n",
        "len(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa4QwdeMdxpS"
      },
      "source": [
        "import json\n",
        "with open('Downloads/GodzillavsKong.json', 'w') as json_file:\n",
        "    json.dump(r, json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_K2KOtXaQWW"
      },
      "source": [
        "## Real-time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDWl0IOxaUSj"
      },
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, clear_output\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.streaming import DataStreamReader\n",
        "import html\n",
        "from pyspark.sql.functions import col, when , regexp_replace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSIZhq0afL0i"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q5VNly3eFIp"
      },
      "source": [
        "IN_PATH='/content/drive/MyDrive/bigdata/BigData_Project/CrawldataIMDB'\n",
        "#timestampformat='EEE MMM dd HH:mm:ss zzzz yyyy'\n",
        "spark.sql('set spark.sql.legacy.timeParserPolicy=LEGACY')\n",
        "spark= SparkSession.builder.appName(\"StructuredStreamingExample\").getOrCreate()\n",
        "spark.conf.set('spark.sql.legacy.timeParserPolicy',\"LEGACY\")\n",
        "schema=spark.read.json(IN_PATH).limit(10).schema\n",
        "spark_reader=spark.readStream.schema(schema)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H37kJnLueFPh"
      },
      "source": [
        "streaming_data_raw=(spark_reader.json(IN_PATH).select(f.col('date').alias('timestamp'),f.col('reviewer_name').alias('user'),f.col('text').alias('review_detail'),).coalesce(1))\n",
        "stream_writer=(streaming_data_raw.writeStream.queryName('data').trigger(once=True).outputMode('append').format('memory'))\n",
        "query=stream_writer.start()\n",
        "display(spark.sql(f\"SELECT * from {query.name}\").show())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGBDXMDIfeD2"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZejYygh-eFSZ"
      },
      "source": [
        "sentiment_model=PipelineModel.load('/content/drive/MyDrive/bigdata/DL_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40nhXfuaeFZs"
      },
      "source": [
        "raw_sentiment=sentiment_model.transform(streaming_data_clean)\n",
        "sentiment=raw_sentiment.select('timestamp','user','review_detail','probability')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOei4lape412"
      },
      "source": [
        "from pyspark.ml.functions import vector_to_array\n",
        "final = sentiment.select('timestamp','user','review_detail',\"probability\")\\\n",
        ".withColumn(\"probability\",vector_to_array(f.col(\"probability\")))\\\n",
        ".withColumn(\"probability\",f.element_at(f.col(\"probability\"),-1))\n",
        "result = final.withColumn(\"sentiment\",\n",
        "                        f.when(f.col(\"probability\") < 0.475,'negative')\n",
        "                        .when((f.col(\"probability\") >= 0.475) & (f.col(\"probability\") <= 0.675),'neutral')\n",
        "                        .when(f.col(\"probability\") > 0.675,'positive')\n",
        "                        .otherwise(f.col(\"probability\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G58oWxyOe8kG"
      },
      "source": [
        "result=result.select('timestamp','user','review_detail','sentiment')\n",
        "sentiment_count_result=result.groupBy(\"sentiment\").agg(f.count(\"sentiment\").alias(\"count\")).sort(\"count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfCyuawie-q9"
      },
      "source": [
        "stream_writer1=(result.writeStream.queryName('result').trigger(processingTime='5 seconds').outputMode('append').format('memory'))\n",
        "query1=stream_writer1.start()\n",
        "stream_writer2=(sentiment_count_result.writeStream.queryName('data').trigger(processingTime='5 seconds').outputMode('complete').format('memory'))\n",
        "query2=stream_writer2.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTeXOGFgfCk-"
      },
      "source": [
        "### Demo real-time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97PlafJufBpF"
      },
      "source": [
        "if raw_sentiment.isStreaming:\n",
        "    from time import sleep\n",
        "    for x in range(0,2000):\n",
        "        try:\n",
        "            if not query1.isActive:\n",
        "                print('Query not active')\n",
        "                break\n",
        "            print('Showing live view refreshed every 5 seconds')\n",
        "            print(f\"Seconds passed: {x*5}\")\n",
        "            result1=spark.sql(f\"SELECT * from {query1.name}\")\n",
        "            result2=spark.sql(f\"SELECT * from {query2.name}\")\n",
        "            print(len(result1.toPandas()))\n",
        "            display(result1.toPandas())\n",
        "            display(result2.toPandas())\n",
        "            sleep(2)\n",
        "            clear_output(wait=True)\n",
        "        except KeyboardInterrupt:\n",
        "            print('break')\n",
        "            break\n",
        "    print('Live view ended...')\n",
        "else:\n",
        "    print(\"Not streaming\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}